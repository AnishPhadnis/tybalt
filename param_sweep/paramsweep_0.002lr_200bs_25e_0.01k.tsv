	loss	val_loss	learning_rate	batch_size	epochs	kappa
0	2990.45328817	4054.38236156	0.002	200	25	0.01
1	2811.71623359	2914.867968	0.002	200	25	0.01
2	2779.019773	2797.55518839	0.002	200	25	0.01
3	2761.21213644	2776.81309845	0.002	200	25	0.01
4	2750.23569333	2761.15104182	0.002	200	25	0.01
5	2742.34515156	2749.82118403	0.002	200	25	0.01
6	2736.02631137	2744.50736296	0.002	200	25	0.01
7	2730.56364435	2737.99420691	0.002	200	25	0.01
8	2726.43638221	2730.66406577	0.002	200	25	0.01
9	2722.42825713	2725.44572703	0.002	200	25	0.01
10	2718.70166711	2734.48674639	0.002	200	25	0.01
11	2715.45900087	2722.01004711	0.002	200	25	0.01
12	2712.91434516	2719.3090965	0.002	200	25	0.01
13	2711.13061964	2714.36665207	0.002	200	25	0.01
14	2708.16577011	2713.31059169	0.002	200	25	0.01
15	2706.28217334	2710.28162531	0.002	200	25	0.01
16	2704.2806816	2707.21586186	0.002	200	25	0.01
17	2702.3472138	2706.49607274	0.002	200	25	0.01
18	2700.60851051	2701.7277818	0.002	200	25	0.01
19	2698.59520963	2700.77963624	0.002	200	25	0.01
20	2698.10977966	2703.4752405	0.002	200	25	0.01
21	2696.63943501	2700.17751638	0.002	200	25	0.01
22	2695.56344425	2700.47431622	0.002	200	25	0.01
23	2694.2271691	2697.85666331	0.002	200	25	0.01
24	2692.73856422	2696.30263074	0.002	200	25	0.01
